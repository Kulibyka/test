# Postman collection guide

Use these examples to exercise all HTTP endpoints exposed by the services when running locally via `docker compose up --build` (messages-service on port **8080**, llm-service on port **8081**). Replace `{{id}}` placeholders with real message IDs from responses.

## Full workflow sequence (recommended order)

1. **Check health**: call `GET /healthz` on both services to ensure they are up.
2. **Submit an email**: `POST /process` on `messages-service` to queue an incoming message; capture the returned `id`.
3. **Send to the LLM**: optionally forward the raw payload to `llm-service` via `POST /process` (or let background processing handle it) to obtain a model response.
4. **Validate LLM output**: `POST /validate_processed_message` on `messages-service` with the `classification` and `model_answer` for the queued `id`.
5. **Review stored messages**: `GET /processed` to confirm the message record contains the expected classification/model answer.
6. **Approve the message** (if acceptable): `POST /approve` with the same `id`.
7. **Add or override assistant reply** (optional): `POST /add-assistant-response` if a manual/updated assistant response is needed, optionally marking it processed.

After step 6 or 7, the message should be marked as processed/approved with the final assistant response available for downstream use.

## messages-service (`http://localhost:8080`)

### Health check
- **Method:** `GET`
- **URL:** `http://localhost:8080/healthz`
- **Purpose:** confirm service availability. Expect `{ "status": "ok" }`.

### Submit incoming email
- **Method:** `POST`
- **URL:** `http://localhost:8080/process`
- **Headers:** `Content-Type: application/json`
- **Body (raw JSON):**
  ```json
  {
    "input": "Hi, I'd like to schedule a demo next week.",
    "from": "sender@example.com",
    "to": "support@example.com",
    "id": "{{optional-custom-uuid}}",
    "received_at": "2024-07-01T12:00:00Z"
  }
  ```
- **Notes:** `id` and `received_at` are optional; if omitted they are generated by the service. Successful response is `202 Accepted` with `{ "status": "queued", "id": "<generated-id>" }`.

### Provide LLM result for a message
- **Method:** `POST`
- **URL:** `http://localhost:8080/validate_processed_message`
- **Headers:** `Content-Type: application/json`
- **Body (raw JSON):**
  ```json
  {
    "id": "{{id}}",
    "classification": "important",
    "model_answer": {"summary": "User wants a demo", "priority": "high"}
  }
  ```
- **Notes:** Use the `id` returned from `/process`. Non-empty `classification` and valid JSON `model_answer` are required. Success returns `{ "status": "accepted" }`.

### List processed messages
- **Method:** `GET`
- **URL:** `http://localhost:8080/processed`
- **Purpose:** retrieve processed emails. Response body contains a `messages` array with stored fields like `classification`, `model_answer`, `assistant_resp`, `is_approved`, etc.

### Approve a message
- **Method:** `POST`
- **URL:** `http://localhost:8080/approve`
- **Headers:** `Content-Type: application/json`
- **Body (raw JSON):**
  ```json
  {
    "id": "{{id}}"
  }
  ```
- **Notes:** Marks the message as approved. Response is `{ "status": "approved", "id": "{{id}}" }`.

### Add or override assistant response
- **Method:** `POST`
- **URL:** `http://localhost:8080/add-assistant-response`
- **Headers:** `Content-Type: application/json`
- **Body (raw JSON):**
  ```json
  {
    "id": "{{id}}",
    "assistant_response": {"summary": "Manual operator reply"},
    "mark_processed": true
  }
  ```
- **Notes:** `assistant_response` must be valid JSON. Set `mark_processed` to `true` to flag the message as processed alongside the manual answer. Response is `{ "status": "saved", "id": "{{id}}" }`.

## llm-service (`http://localhost:8081`)

### Health check
- **Method:** `GET`
- **URL:** `http://localhost:8081/healthz`
- **Purpose:** confirm service availability. Expect `200 OK` with body `ok`.

### Forward message to LLM
- **Method:** `POST`
- **URL:** `http://localhost:8081/process`
- **Headers:** `Content-Type: text/plain`
- **Body (raw text):**
  ```
  {"id":"{{id}}","input":"Hi, I'd like to schedule a demo next week."}
  ```
- **Notes:** The handler forwards the raw body to OpenRouter using the configured prompt; it extracts the first JSON object from the model output and returns it if valid. Invalid or missing JSON results in `400 Bad Request`.
